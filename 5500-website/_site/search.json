[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Monitoring the Metro",
    "section": "",
    "text": "The Washington Metropolitan Area Transit Authority’s (WMATA) rail system serves hundreds of thousands of riders per day, many of whom rely on it as their primary form of transport to work or school. In fact, an estimated 37.4% of Washington, D.C. residents are public transit commuters, a percentage that is second in the US, only behind New York City.1 Thus, the demand for reliable, fast, and punctual service is obvious. As an effort to assist riders in planning their trips, WMATA makes certain service information public, including the estimated arrival times of trains. However, simply relying on integer prediction values at a given time could leave out valuable information about when trains might actually arrive. To better understand the quality of this service, this project uses an ETL pipeline that leverages WMATA’s public API2 to extract rail predictions, calculates actual arrival times in relation to predicted times, and visualizes results based on a variety of variables.\nWMATA’s API specifically provides a dataset of “Next Trains”, which return a dictionary of individual trains, along with their number of cars, destination, line (e.g., Red, Silver, etc.), and the estimated time of arrival to each subsequent station. The Extract step of the ETL pipeline is to call this API every 30 seconds to ensure each train’s prediction sequence and arrival time are accounted for. The Transform step entails labelling which train is next to arrive for each station/line/direction combination so that when a corresponding train does arrive, the actual arrival time is recorded. Calculations are then performed to obtain the difference between the actual time a train took to arrive and its predicted arrival time. Finally, the Load step saves all these transformations locally in a data frame to be retroactively updated as more predictions come in and trains continue to arrive. The resultant data is visualized via a Streamlit application, which shows metrics such as prediction error and time between trains, which can be filtered to evaluate which lines, stations, and prediction times have the best performance.\nThis Streamlit application serves as the final artifact for this project, offering valuable insight to potential WMATA passengers about what to expect from train arrivals. This application shows a probability distribution of prediction error based on actual arrival times, a probability distribution of the time between train arrivals at each station, and box plots that differentiate prediction errors based on each train’s predicted time to arrive. Visualizing punctuality interactively allows us to analyze overall performance of the entire rail system, as well as identify distinctions between different rail lines, stations, or times of day."
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Monitoring the Metro",
    "section": "",
    "text": "The Washington Metropolitan Area Transit Authority’s (WMATA) rail system serves hundreds of thousands of riders per day, many of whom rely on it as their primary form of transport to work or school. In fact, an estimated 37.4% of Washington, D.C. residents are public transit commuters, a percentage that is second in the US, only behind New York City.1 Thus, the demand for reliable, fast, and punctual service is obvious. As an effort to assist riders in planning their trips, WMATA makes certain service information public, including the estimated arrival times of trains. However, simply relying on integer prediction values at a given time could leave out valuable information about when trains might actually arrive. To better understand the quality of this service, this project uses an ETL pipeline that leverages WMATA’s public API2 to extract rail predictions, calculates actual arrival times in relation to predicted times, and visualizes results based on a variety of variables.\nWMATA’s API specifically provides a dataset of “Next Trains”, which return a dictionary of individual trains, along with their number of cars, destination, line (e.g., Red, Silver, etc.), and the estimated time of arrival to each subsequent station. The Extract step of the ETL pipeline is to call this API every 30 seconds to ensure each train’s prediction sequence and arrival time are accounted for. The Transform step entails labelling which train is next to arrive for each station/line/direction combination so that when a corresponding train does arrive, the actual arrival time is recorded. Calculations are then performed to obtain the difference between the actual time a train took to arrive and its predicted arrival time. Finally, the Load step saves all these transformations locally in a data frame to be retroactively updated as more predictions come in and trains continue to arrive. The resultant data is visualized via a Streamlit application, which shows metrics such as prediction error and time between trains, which can be filtered to evaluate which lines, stations, and prediction times have the best performance.\nThis Streamlit application serves as the final artifact for this project, offering valuable insight to potential WMATA passengers about what to expect from train arrivals. This application shows a probability distribution of prediction error based on actual arrival times, a probability distribution of the time between train arrivals at each station, and box plots that differentiate prediction errors based on each train’s predicted time to arrive. Visualizing punctuality interactively allows us to analyze overall performance of the entire rail system, as well as identify distinctions between different rail lines, stations, or times of day."
  },
  {
    "objectID": "index.html#the-etl-process",
    "href": "index.html#the-etl-process",
    "title": "Monitoring the Metro",
    "section": "The ETL Process",
    "text": "The ETL Process\nThe following process uses data from three 30-minute time windows of WMATA rail predictions, all from Thursday, May 1st, 2025. The runs were scheduled at the following times:\n\n2:00 P.M. EDT\n5:30 P.M. EDT\n10:00 P.M. EDT\n\nThis methodology was chosen to limit the volume of data and avoid any computational limitations of storing data locally, so only an hour and a half of rail predictions are present. While this is obviously not a representative sample of WMATA’s general performance, these time choices offer one mid-day window, one rush-hour window, and one nighttime window during non-peak hours. This will serve as a Minimum Viable Product and eventually allow us to use the time of day as a variable when evaluating performance.\n\nPipeline\nExtract: The fetch_data task is quite simple. It executes an API call to get a current snapshot of rail predictions, adds a timestamp, and determines whether it’s during peak hours using the is_peak_hour function. Seven new columns are added in this step:\n\nCallTime: The timestamp of the API call\nPeak: Whether it’s during peak hours (boolean)\nLeftYet: Whether the train has left yet (boolean, defaults to false)\nIsNext: Whether the train is the next to arrive at that station (boolean, defaults to false)\nBRD_Time: The actual time of arrival (empty by default)\nTimeToBRD: The difference between the API call time and the arrival time (empty by default)\nDiff: The difference between TimeToBRD and the predicted minutes away (empty by default)\n\nFinally, data is returned as a Pandas dataframe for further transformation.\nTransform: Much of the data transformation in this pipeline stems from the fact that trains from the WMATA API do not have unique identifiers, and are therefore more difficult to track across multiple calls. In fact, the observational unit is not just unique trains, but unique trains by location; meaning one train will have multiple records for its estimated time to each subsequent station. As a result of this complexity, the transform_batch function serves as this project’s implementation of data validation, as it uses processes to track which trains are next to arrive and which have already left by matching based on several variables in lieu of unique identifiers.\nThe transform_batch task takes in three dataframes: current_batch (the data just acquired from the extract step), last_batch (the previous run’s new data, used to distinguish new arrivals from duplicates), and all_trains (all current and prior trains, so that past trains can be updated when they arrive).\nThis function starts by recognizing which trains are next to arrive at each station. For each group of trains (by Line, LocationName, Destination) in the current batch, the train with the lowest numeric Min value that hasn’t left yet is marked as IsNext. It then detects new arrivals by taking trains where Min is either “ARR” (arriving) or “BRD” (boarding) and comparing them to the last batch to remove arrivals that were accounted for previously.\nBy obtaining each new arrival, we can find prior trains in the same group (by Line, LocationName, Destination) that were previously marked IsNext=True (meaning they were the next train to arrive) and updates them to LeftYet=True. For all of these instances, the function adds the current batch’s call time as BRD_Time and then calculates TimeToBRD and Diff to get prediction accuracy.\nFinally, we update IsNext for every prior batch. All IsNext values are reset and recalculated across all trains that haven’t left yet, ensuring that the lowest Min values for each train grouping (by Line, LocationName, Destination) are identified as the next to arrive. Ultimately, the combined dataframe containing every current and past train is returned.\nLoad: After each run, the save_data task is run. This task takes in all_trains (the dataframe of every current and past train with all transformation implemented) and current_batch (the dataframe of trains just from the most recent API call) as inputs. It saves both locally as .csv files, overwriting the previous data that was stored there. This is done so that when a new run is executed, past data can be pulled in again and transformed based on new train arrivals. Specifically, current_batch is stored so that we can ensure that arrivals in the next API call are new arrivals, not duplicates.\nFlow: Lastly, the main_pipeline function is what calls all of these tasks. This function first performs the Extract step by getting current_batch from the fetch_data task. It then calls the load_past_data task, which reads in the two saved .csv files as dataframes to enable them to be used as arguments in the transform_batch function. The Transform step is then executed using these three dataframes to receive an updated dataframe containing transformed data of all current and past trains called updated_all_trains. Finally, the Load step is executed by calling save_data and saving the dataframes of all trains and the current batch to be recalled in the next run.\nThe following code cell contains all of the functionalities described above.\n\n\nCode\n%%writefile pipeline.py\nimport requests\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict\nfrom pandas import Timestamp\nfrom prefect import flow, task\nimport os\n\n# distinguishing peak hours\ndef is_peak_hour(dt: datetime) -&gt; bool:\n    return dt.weekday() &lt; 5 and dt.hour &gt;= 5 and dt.hour &lt; 21 or (dt.hour == 21 and dt.minute &lt;= 30)\n\n# calling WMATA API and converting data to pandas dataframe\n@task\ndef fetch_data():\n    api_key = \"4b20a99005d64434999fae74f7ba3f7c\"\n    url = \"http://api.wmata.com/StationPrediction.svc/json/GetPrediction/All\"\n    headers = {\"api_key\": api_key}\n    response = requests.get(url, headers=headers)\n    data = response.json()\n    \n    call_time = datetime.now()\n    peak = is_peak_hour(call_time)\n    \n    # dict object for each train\n    trains = []\n    for train in data.get(\"Trains\", []):\n        if train.get(\"Min\") == \"---\":\n            continue\n        \n        entry = {\n            \"Car\": train.get(\"Car\"),\n            \"Destination\": train.get(\"Destination\"),\n            \"DestinationCode\": train.get(\"DestinationCode\"),\n            \"DestinationName\": train.get(\"DestinationName\"),\n            \"Group\": train.get(\"Group\"),\n            \"Line\": train.get(\"Line\"),\n            \"LocationCode\": train.get(\"LocationCode\"),\n            \"LocationName\": train.get(\"LocationName\"),\n            \"Min\": train.get(\"Min\"),\n            \"CallTime\": call_time,\n            \"Peak\": peak,\n            \"LeftYet\": False,\n            \"IsNext\": False,\n            \"BRD_Time\": None,\n            \"TimeToBRD\": None,\n            \"Diff\": None\n        }\n        trains.append(entry)\n    \n    # convert to pandas dataframe\n    return pd.DataFrame(trains)\n\n# pull all past trains to edit based on new arrivals\n@task\ndef load_past_data():\n    if os.path.exists(\"all_trains2.csv\"):\n        all_trains = pd.read_csv(\"all_trains2.csv\", parse_dates=[\"CallTime\", \"BRD_Time\"])\n    else:\n        all_trains = pd.DataFrame()\n\n    if os.path.exists(\"last_batch2.csv\"):\n        last_batch = pd.read_csv(\"last_batch2.csv\", parse_dates=[\"CallTime\"])\n    else:\n        last_batch = pd.DataFrame()\n\n    return all_trains, last_batch\n\n# save all current trains to be pulled into next batch\n@task\ndef save_data(all_trains: pd.DataFrame, current_batch: pd.DataFrame):\n    all_trains.to_csv(\"all_trains2.csv\", index=False)\n    current_batch.to_csv(\"last_batch2.csv\", index=False)\n\n# transform step of ETL\ndef transform_batch(current_batch: pd.DataFrame, all_trains: pd.DataFrame, last_batch: pd.DataFrame) -&gt; pd.DataFrame:\n    from collections import defaultdict\n    from datetime import datetime\n\n    # data validation for new columns\n    for col in ['IsNext', 'LeftYet', 'BRD_Time', 'TimeToBRD', 'Diff']:\n        for df in [current_batch, all_trains]:\n            if col not in df.columns:\n                df[col] = None\n\n    current_batch['IsNext'] = False\n    current_batch['LeftYet'] = False\n\n    # grouping trains by line, location, and destination to account for lack of unique identifiers\n    group_keys = ['Line', 'LocationName', 'Destination']\n    \n    def safe_to_int(value):\n        try:\n            return int(value)\n        except ValueError:\n            return None\n    # filter non-numeric Min values (\"ARR\" or \"BRD\") and make IsNext=True for the train with the lowest Min for trains that haven't left yet in each group\n    for key, group in current_batch.groupby(group_keys):\n        not_left = group[~group['LeftYet']]\n\n        digit_mins = not_left[not_left['Min'].apply(lambda x: safe_to_int(x) is not None)]\n\n        if not digit_mins.empty:\n            min_val = digit_mins['Min'].apply(safe_to_int).min()\n            idx = digit_mins[digit_mins['Min'].apply(safe_to_int) == min_val].index\n            current_batch.loc[idx, 'IsNext'] = True\n\n    # get list of arrivals, remove ones with arrivals in the last batch to avoid duplicates\n    arrival_keys = set(map(tuple, current_batch[current_batch['Min'].isin(['ARR', 'BRD'])][group_keys].values))\n    previous_arrival_keys = set(map(tuple, last_batch[last_batch['Min'].isin(['ARR', 'BRD'])][group_keys].values))\n    new_arrivals = arrival_keys - previous_arrival_keys\n\n    arrival_time = current_batch['CallTime'].iloc[0] if not current_batch.empty else datetime.now()\n\n    # for each new arrival, update IsNext and LeftYet retroactively\n    for key in new_arrivals:\n        # creating masks to group data by line/location/destination and exclude departed trains\n        mask_past = (\n            (all_trains['Line'] == key[0]) &\n            (all_trains['LocationName'] == key[1]) &\n            (all_trains['Destination'] == key[2]) &\n            (~all_trains['LeftYet']) &\n            (all_trains['Min'].apply(lambda x: safe_to_int(x) is not None))\n        )\n        # check all batches by getting unique call times, then set IsNext=True for minimum estimated minutes\n        for ct in all_trains[mask_past]['CallTime'].unique():\n            ct_mask = mask_past & (all_trains['CallTime'] == ct)\n            if not all_trains[ct_mask].empty:\n                digit_ct_mask = ct_mask & all_trains['Min'].apply(lambda x: safe_to_int(x) is not None)\n\n                if not all_trains[digit_ct_mask].empty:\n                    min_val = all_trains.loc[digit_ct_mask, 'Min'].apply(safe_to_int).min()\n                    is_next_mask = digit_ct_mask & (all_trains['Min'].apply(safe_to_int) == min_val)\n                    all_trains.loc[is_next_mask, 'IsNext'] = True\n\n        # create masks for retroactively updating\n        retro_mask = (\n            (all_trains['Line'] == key[0]) &\n            (all_trains['LocationName'] == key[1]) &\n            (all_trains['Destination'] == key[2]) &\n            (all_trains['IsNext']) &\n            (~all_trains['LeftYet'])\n        )\n\n        # make LeftYet=true, then add boarding time and calculate performance\n        all_trains.loc[retro_mask, 'LeftYet'] = True\n        all_trains.loc[retro_mask, 'BRD_Time'] = arrival_time\n\n        valid_min_mask = retro_mask & all_trains['Min'].apply(lambda x: safe_to_int(x) is not None)\n        all_trains.loc[valid_min_mask, 'TimeToBRD'] = (\n            (arrival_time - all_trains.loc[valid_min_mask, 'CallTime']).dt.total_seconds() / 60\n        )\n        all_trains.loc[valid_min_mask, 'Diff'] = (\n            all_trains.loc[valid_min_mask, 'TimeToBRD'] -\n            all_trains.loc[valid_min_mask, 'Min'].apply(safe_to_int)\n        )\n\n    # reset IsNext to false so only next train gets re-computed with True value\n    all_trains['IsNext'] = False\n    combined = pd.concat([all_trains, current_batch], ignore_index=True)\n\n    valid_min_combined = combined[combined['Min'].apply(lambda x: safe_to_int(x) is not None)]\n    call_groups = valid_min_combined.groupby(['CallTime', 'Line', 'LocationName', 'Destination'])\n\n    # get lowest Min for each group and mark those as the next train for each line/location/destination combo\n    for _, group in call_groups:\n        min_val = group['Min'].apply(safe_to_int).min()\n        idx_to_update = group[group['Min'].apply(safe_to_int) == min_val].index\n        combined.loc[idx_to_update, 'IsNext'] = True\n\n    return combined\n\n@flow\ndef main_pipeline():\n    # extract\n    current_batch = fetch_data()\n    # transform\n    all_trains, last_batch = load_past_data()\n    updated_all_trains = transform_batch(current_batch, all_trains, last_batch)\n    # load\n    save_data(updated_all_trains, current_batch)\n\n\n\n\nPrefect Deployment\nThe following code cell writes to serve.py, which is the file that gets executed in order to schedule runs in Prefect and execute the functions defined in pipeline.py. This process defines both duration time of 30 minutes and an interval time of 30 seconds, indicating that the pipeline should be run every 30 seconds for 30 minutes (i.e., 60 times). Due to concerns with the transform step taking a prohibitively long amount of time, which could result in a run starting before the prior run had loaded its data to be extracted for the next run, a safeguard is in place to run either every 30 seconds or when the previous run has been completed, whichever comes last. Luckily, this proved to be unnecessary for the short deployment durations of 30 minutes, which limited the size of the loaded data and thus the runtime of the transform step.\n\n\nCode\n%%writefile serve.py\nimport time\nfrom datetime import datetime, timedelta\nfrom pipeline import main_pipeline\n\ndef run_schedule_for_duration(interval_seconds=30, duration_minutes=30):\n    end_time = datetime.now() + timedelta(minutes=duration_minutes)\n    run_count = 0\n\n    while datetime.now() &lt; end_time:\n        loop_start = datetime.now()\n        print(f\"\\n[{loop_start}] Starting pipeline iteration {run_count + 1}\")\n        \n        main_pipeline()\n        run_count += 1\n        \n        elapsed = (datetime.now() - loop_start).total_seconds()\n        sleep_time = max(0, interval_seconds - elapsed)\n        if sleep_time &gt; 0:\n            print(f\"[{datetime.now()}] Sleeping for {sleep_time:.2f} seconds...\")\n            time.sleep(sleep_time)\n\n    print(f\"\\n[{datetime.now()}] Completed {run_count} iterations in {duration_minutes} minutes.\")\n\nif __name__ == \"__main__\":\n    run_schedule_for_duration()\n\n\nBelow is a screenshot of a sample run in Prefect with all of these implementations in action. This is one of 180 total runs (60 for each deployment).\n\n\n\nExample Prefect Run\n\n\n\n\nVisualizing in Streamlit\nThis code cell writes to streamlit_app.py, which is responsible for reading in data after the runs had completed and visualizing the results. This process entails reading three .csv files (from each deployment time), labelling them based on which time window they came from, and combining into a larger dataframe.\nPrior to visualization, a few data manipulation steps were implemented. First of all, the data is filtered to only include trains for which the arrival time was accounted, as those are the only ones whose performance can be measured. Secondly, a dataframe only containing unique arrivals was created with a GapMin variable in order to create a visualization of the gap between arrivals at each station. The visualizations are all created using Plotly in Python, and will be explained in greater detail in the next section.\n\n\nCode\n%%writefile streamlit_app.py\nimport streamlit as st\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# read in 3 dataframes and concatenate\nst.set_page_config(layout=\"wide\")\ndf1 = pd.read_csv(\"final-project/all_trains1.csv\")\ndf1['Execution'] = 1\ndf2 = pd.read_csv(\"final-project/all_trains2.csv\")\ndf2['Execution'] = 2\ndf3 = pd.read_csv(\"final-project/all_trains3.csv\")\ndf3['Execution'] = 3\n\ndf = pd.concat([df1, df2, df3])\n\n# filter so only trains with arrivals are kept\ndf[\"Diff\"] = df[\"Diff\"].round()\ndf = df[~df[\"Line\"].isin([\"--\", \"No\"])]\n\nst.sidebar.header(\"Filter Options\")\n\n# get train lines, locations, and Min values\nline_options = sorted(df[\"Line\"].dropna().unique())\nlocation_options = sorted(df[\"LocationName\"].dropna().unique())\nmin_range = df[\"Min\"].apply(lambda x: int(x) if str(x).isdigit() else None).dropna()\n\n# filters for line, location, and Min values\nselected_line = st.sidebar.selectbox(\"Select Rail Line\", [\"All\"] + line_options)\nselected_location = st.sidebar.selectbox(\"Select Station Location\", [\"All\"] + location_options)\nmin_slider = st.sidebar.slider(\"Estimated Minutes Away\", int(min_range.min()), int(min_range.max()), (int(min_range.min()), int(min_range.max())))\n\n# radio button filter for peak hours\npeak_filter = st.sidebar.radio(\"Peak Hours?\", options=[\"All\", \"Peak Hours\", \"Off Peak\"])\nfiltered_df = df.copy()\n\n# update color based on line selection\nplot_color = \"#ff4b4b\"\ntitle_color = \"All Lines\"\ntitle_location = \"All Stations\"\nif selected_line != \"All\":\n    filtered_df = filtered_df[filtered_df[\"Line\"] == selected_line]\n    if selected_line==\"BL\":\n        plot_color = \"#0279c1\"\n        title_color = \"Blue Line\"\n    elif selected_line==\"OR\":\n        plot_color = \"#f78e1d\"\n        title_color = \"Orange Line\"\n    elif selected_line==\"SV\":\n        plot_color = \"#d8d8d8\"\n        title_color = \"Silver Line\"\n    elif selected_line==\"YL\":\n        plot_color = \"#ffdd04\"\n        title_color = \"Yellow Line\"\n    elif selected_line==\"GR\":\n        plot_color = \"#01a94f\"\n        title_color = \"Green Line\"\n    elif selected_line==\"RD\":\n        plot_color = \"#ee4135\"\n        title_color = \"Red Line\"\nif selected_location != \"All\":\n    filtered_df = filtered_df[filtered_df[\"LocationName\"] == selected_location]\n    title_location = selected_location\n\n# filter based on user selections\nfiltered_df = filtered_df[filtered_df[\"Min\"].apply(lambda x: str(x).isdigit())]\nfiltered_df[\"Min\"] = filtered_df[\"Min\"].astype(int)\nfiltered_df = filtered_df[\n    (filtered_df[\"Min\"] &gt;= min_slider[0]) & (filtered_df[\"Min\"] &lt;= min_slider[1])\n]\n\nif peak_filter == \"Peak Hours\":\n    filtered_df = filtered_df[filtered_df[\"Peak\"] == True]\nelif peak_filter == \"Off Peak\":\n    filtered_df = filtered_df[filtered_df[\"Peak\"] == False]\n\n# get arrivals to calculate time between arrivals\narrivals_df = filtered_df.dropna(subset=[\"BRD_Time\"]).copy()\narrivals_df[\"BRD_Time\"] = pd.to_datetime(arrivals_df[\"BRD_Time\"])\narrivals_df = arrivals_df.drop_duplicates(\n    subset=[\"Line\", \"LocationName\", \"Destination\", \"BRD_Time\"]\n)\n\narrivals_df = arrivals_df.sort_values(by=[\"Line\", \"LocationName\", \"Destination\", \"BRD_Time\"])\n\n# create GapMin for each arrival gap\narrivals_df[\"GapMin\"] = (\n    arrivals_df.groupby([\"Line\", \"LocationName\", \"Destination\", \"Execution\"])[\"BRD_Time\"]\n    .diff()\n    .dt.total_seconds()\n    .div(60)\n)\n\narrivals_df = arrivals_df.dropna(subset=[\"GapMin\"])\n\n# plots in streamlit using plotly\nst.title(\"WMATA Rail Punctuality Analysis\")\n\nst_col1, st_col2 = st.columns(2)\n\nwith st_col1:\n    hist_fig = px.histogram(\n        filtered_df,\n        x=\"Diff\",\n        nbins=int(filtered_df[\"Diff\"].max() - filtered_df[\"Diff\"].min()) + 1,\n        title=\"Distribution of Prediction Error - \" + title_color + \" - \" + title_location,\n        labels={\"Diff\": \"Actual Arrival minus Predicted Arrival (minutes)\", \"count\": \"Count\"},\n        color_discrete_sequence=[plot_color],\n        histnorm=\"probability\"\n    )\n    hist_fig.update_layout(bargap=0.05,height=350, margin=dict(t=30, b=30),yaxis_title=\"Proportion\")\n    st.plotly_chart(hist_fig, use_container_width=True)\n\ngap_filtered = arrivals_df.copy()\nif selected_line != \"All\":\n    gap_filtered = gap_filtered[gap_filtered[\"Line\"] == selected_line]\nif selected_location != \"All\":\n    gap_filtered = gap_filtered[gap_filtered[\"LocationName\"] == selected_location]\n\nwith st_col2:\n    gap_fig = px.histogram(\n        gap_filtered,\n        x=\"GapMin\",\n        nbins=30,\n        title=\"Time Between Train Arrivals - \" + title_color + \" - \" + title_location,\n        labels={\"GapMin\": \"Time Between Trains (minutes)\"},\n        color_discrete_sequence=[plot_color],\n        histnorm=\"probability\"\n    )\n    gap_fig.update_layout(\n        bargap=0.05,\n        height=350,\n        margin=dict(t=30, b=30),\n        xaxis_title=\"Gap (minutes)\",\n        yaxis_title=\"Proportion\"\n    )\n    st.plotly_chart(gap_fig, use_container_width=True)\n\navg_diff = filtered_df.groupby(\"Min\", as_index=False)[\"Diff\"].mean()\n\nbox_fig = px.box(\n    filtered_df,\n    x=\"Min\",\n    y=\"Diff\",\n    points=\"outliers\",\n    title= \"Prediction Error Box Plots by Estimated Minutes Out - \" + title_color + \" - \" + title_location,\n    labels={\"Min\": \"Estimated Minutes Out\", \"Diff\": \"Prediction Error (minutes)\"},\n    color_discrete_sequence=[plot_color]\n)\n\nbox_fig.update_yaxes(\n    zeroline=True,\n    zerolinewidth=1,\n    zerolinecolor=\"black\"\n)\nbox_fig.update_layout(height=350, margin=dict(t=30, b=30))\nst.plotly_chart(box_fig, use_container_width=True)"
  },
  {
    "objectID": "index.html#artifact",
    "href": "index.html#artifact",
    "title": "Monitoring the Metro",
    "section": "Artifact",
    "text": "Artifact\nThe automated result of this ETL pipeline is a final .csv file which contains every train from the specified deployment window, along with the actual arrival times and all other calculations completed in the transform step. To visualize this data, this project’s artifact is Streamlit application which offers interactive plots showing some key insights regarding WMATA’s train arrivals. Due to persisting issues embedding the application in this document, below is a link to the interactive application with a screenshot of its interface:\nLink to Streamlit application\n\n\n\nScreenshot of Streamlit application\n\n\nThe following features exist in this application:\n\nSidebar: This allows users to filter based on rail line, station, estimated minutes away (to see predictions from a certain range of minutes out), and peak hours. These will dynamically update what appears on the screen, along with corresponding color changes if the user filters by rail line. The titles of the plots will also change to reflect the user’s selection.\nDistribution of Prediction Error: This displays the distribution of the Diff variable, which is the actual arrival time minus the expected arrival time of each train. Since WMATA gives predictions as full minutes, these are binned by nearest integer.\nTime between Train Arrivals: Similarly, this is a histogram of the distribution of time between train arrivals, measuring the difference between the arrival time of each train with that of the previous train with the same line/location/destination combination.\nPrediction Error Box Plots by Estimated Minutes Out: These are box plots that show the distribution of prediction error, with one box plot for each Min value. Essentially, it shows box plots for each possible estimated arrival time."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "Monitoring the Metro",
    "section": "Discussion",
    "text": "Discussion\n\nKey Findings\nFirst looking at the Distribution of Prediction Error plot, we can see that the vast majority (about 88%) of arrivals come within a minute of their predicted time on either side. This remains mostly true for every line, although the yellow line appears to have the lowest proportion within that range. We can also see that as we get further from 0, positive values (meaning the train is late) are more frequent than negative ones. This is intuitive, as there is generally more time to be lost by a slower than average train than time to be gained by a faster than average train.\nAs we adjust the Estimated Minutes Away slider, we can see that predictions are more accurate for smaller arrival predictions, which is also expected. For example, looking at estimations of 6+ minutes, only about 83% of trains arrive within a minute of their predictions. This drops to around 78% for 11+ minutes. It’s clear that this data is properly showing the higher variance in further out predictions.\nNext, we can look at the Time between Train Arrivals histogram, which shows a right-skewed plot with a mode around six minutes between arrivals. The skewness indicates that it is entirely common to see gaps between arrivals even at around 12-13 minutes. Filtering by line paints an interesting picture. Red, Yellow, and Green lines clearly have modes around six minutes with relatively stable distribution patterns, while the most common value for Orange and Silver lines (which mostly share a route) is around 12 minutes. Meanwhile the Blue line shares part of its route with Orange and Silver, and another part with the Yellow line, and appears to have a bimodal distribution mimicking each of its cohabitants’ patterns.\nIf we filter by peak hours, we can see the mode change to around eight minutes for off-peak trains, which reflects an intentional reduction in service during times when fewer passengers are expected.\nThe box plots confirm our suspicion that prediction error generally centers within a minute of 0. In fact, for every estimated minutes out up to 26, neither the upper nor lower quartile values stray outside of this small range. We can see that as the x-axis increases, so does the range between the upper and lower fence, again indicating greater variance for these values.\nOne thing worth noting is that the data tends to skew towards a prediction error of -1 more than 1. This is likely due to the fact that my indicator for a train arriving is when it’s marked “ARR”, which technically only means it’s approaching the station, which will cause the pipeline to give an actual arrival time to a train that is slightly before it actually stopping. Importantly, I didn’t find any instances of trains staying on “ARR” for longer than one run, so it is still mostly accurate in telling us the actual time of arrival; perhaps early by ~30 seconds.\nFinally, another observation is the infrequent yet noticeable presence of exceedingly large prediction error values. As WMATA passengers may know, it is not unheard of for a train to exist but disappear from prediction boards for some amount of time. In our case, these trains would not be accounted for in a particular run, making the train after them the “next” one arriving at a station. If the train is later recorded as having arrived, the previous train (with a larger prediction time) will get marked as arrived by my pipeline for any run where it was the next arriving train, resulting in a large negative prediction error. While this is certainly a data issue that could be remedied, there is an argument that this is a benefit of trusting each API call as correct. After all, passengers do not receive unique identifiers for trains either, and this project is better served as an evaluation tool of the reliability of WMATA’s public information, rather than of train speeds. Nevertheless, it is valuable to understand why such values occur.\n\n\nPotential Improvements\nThe first and most obvious improvement is to carry out this process using a significantly longer time window, which could provide a more representative sample of WMATA train arrivals. While this would be more computationally demanding and perhaps expensive, it may provide actionable insights on performance disparity between lines, locations, or times of day.\nAdditional considerations which would be helped by more data are the volumes and demographics of those served by different parts of WMATA’s rail system. If certain stations could be identified as having better or worse performance, we could analyze how many people are affected by that, and whether certain communities are affected more than others. These findings could be aided by geographic visualizations to give a more contextual picture of how the Washington, D.C. metropolitan area is impacted.\nFinally, implementing a predictive element based on the resulting dataset could offer valuable insight to consumers. Further iterations of this project could use past data to create arrival time probability distributions given a particular train’s line, location, and predicted arrival time, which would offer users information that goes beyond the simple integer value provided by WMATA."
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Monitoring the Metro",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Monitoring the Metro",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nU.S. Census Bureau. “SELECTED ECONOMIC CHARACTERISTICS.” American Community Survey, ACS 5-Year Estimates Data Profiles, Table DP03, 2015, https://data.census.gov/table/ACSDP5Y2015.DP03. Accessed on May 2, 2025.↩︎\nWashington Metropolitan Area Transit Authority API, https://developer.wmata.com/apis↩︎"
  }
]